{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from llamawrapper import LlamaHelper\n",
    "import torch\n",
    "import sys\n",
    "sys.path.append('echo-embeddings')\n",
    "from echo_embeddings import EchoEmbeddingsMistral, EchoPooling, EchoParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c56cd688fde040f98371f1a6f44626fa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "runai = False\n",
    "templates = {\n",
    "    'query': '<s>Instruct:{!%%prompt%%,}\\nQuery:{!%%text%%}\\nQuery again:{%%text%%}{</s>}',\n",
    "    'document': '<s>Document:{!%%text%%}\\nDocument again:{%%text%%}{</s>}',\n",
    "}\n",
    "# Create the model\n",
    "path_to_model = 'jspringer/echo-mistral-7b-instruct-lasttoken'\n",
    "path_to_model = '/dlabscratch1/public/llm_weights/llama2_hf/Llama-2-7b-hf'\n",
    "path_to_model = '/dlabdata1/llama2_hf/Llama-2-7b-hf'\n",
    "if runai:\n",
    "    path_to_model = '/dlabscratch1' + path_to_model\n",
    "model = EchoEmbeddingsMistral.from_pretrained(path_to_model, device_map='auto', load_in_8bit=True)\n",
    "model = model.eval()\n",
    "\n",
    "# Create the parser\n",
    "parser = EchoParser(path_to_model, templates, max_length=1024)\n",
    "\n",
    "# Create the pooling: strategy can either be mean or last\n",
    "pooling = EchoPooling(strategy='mean')\n",
    "\n",
    "# specify the prompt, queries, and documents\n",
    "prompt = 'Retrieve passages that answer the question'\n",
    "queries = [\n",
    "    'What is the capital of France?',\n",
    "    'What is the capital of Deutschland?',\n",
    "]\n",
    "documents = [\n",
    "    'Paris is the capital of France.',\n",
    "    'Berlin is the capital of Germany.',\n",
    "]\n",
    "\n",
    "query_variables = [{'prompt': prompt, 'text': q} for q in queries]\n",
    "document_variables = [{'text': d} for d in documents]\n",
    "\n",
    "query_tagged = [('query', q) for q in query_variables]\n",
    "document_tagged = [('document', d) for d in document_variables]\n",
    "\n",
    "# Get the tokenized embeddings\n",
    "with torch.no_grad():\n",
    "    query_embeddings = pooling(model(parser(query_tagged)))['sentence_embedding']\n",
    "    document_embeddings = pooling(model(parser(document_tagged)))['sentence_embedding']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 4096])\n",
      "tensor([[0.8901, 0.8604],\n",
      "        [0.7886, 0.8203]], device='cuda:0', dtype=torch.float16)\n"
     ]
    }
   ],
   "source": [
    "query_embeddings /= query_embeddings.norm(dim=-1, keepdim=True)\n",
    "document_embeddings /= document_embeddings.norm(dim=-1, keepdim=True)\n",
    "print(query_embeddings.shape)\n",
    "print(query_embeddings @ document_embeddings.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyModel():\n",
    "    def __init__(self, model, parser, pooling):\n",
    "        self.model = model\n",
    "        self.parser = parser\n",
    "        self.pooling = pooling\n",
    "\n",
    "    def encode_queries(self, queries, batch_size=32, **kwargs):\n",
    "        \"\"\"\n",
    "        Returns a list of embeddings for the given sentences.\n",
    "        Args:\n",
    "            queries (`List[str]`): List of sentences to encode\n",
    "            batch_size (`int`): Batch size for the encoding\n",
    "\n",
    "        Returns:\n",
    "            `List[np.ndarray]` or `List[tensor]`: List of embeddings for the given sentences\n",
    "        \"\"\"\n",
    "        model = self.model\n",
    "        parser = self.parser\n",
    "        pooling = self.pooling\n",
    "        batch = []\n",
    "        result = []\n",
    "        for q in queries:\n",
    "            query_variables = {'prompt': prompt, 'text': q}\n",
    "            query_tagged = ('query', query_variables)\n",
    "            batch += [query_tagged]\n",
    "            if len(batch) == batch_size:\n",
    "                with torch.no_grad():\n",
    "                    query_embeddings = pooling(model(parser(batch)))['sentence_embedding']\n",
    "                    result += [query_embeddings.detach().cpu()]\n",
    "                batch = []\n",
    "        if len(batch) > 0:\n",
    "            with torch.no_grad():\n",
    "                query_embeddings = pooling(model(parser(batch)))['sentence_embedding']\n",
    "                result += [query_embeddings.detach().cpu()]\n",
    "        embs = torch.cat(result, dim=0)\n",
    "        embs /= embs.norm(dim=-1, keepdim=True)\n",
    "        return embs\n",
    "\n",
    "    def encode_corpus(self, corpus, batch_size=32, **kwargs):\n",
    "        \"\"\"\n",
    "        Returns a list of embeddings for the given sentences.\n",
    "        Args:\n",
    "            corpus (`List[str]` or `List[Dict[str, str]]`): List of sentences to encode\n",
    "                or list of dictionaries with keys \"title\" and \"text\"\n",
    "            batch_size (`int`): Batch size for the encoding\n",
    "\n",
    "        Returns:\n",
    "            `List[np.ndarray]` or `List[tensor]`: List of embeddings for the given sentences\n",
    "        \"\"\"\n",
    "        model = self.model\n",
    "        parser = self.parser\n",
    "        pooling = self.pooling\n",
    "        \n",
    "        batch = []\n",
    "        result = []\n",
    "        for d in corpus:\n",
    "            document_variables = {'text': d}\n",
    "            document_tagged = ('document', document_variables)\n",
    "            batch += [document_tagged]\n",
    "            if len(batch) == batch_size:\n",
    "                with torch.no_grad():\n",
    "                    query_embeddings = pooling(model(parser(batch)))['sentence_embedding']\n",
    "                    result += [query_embeddings.detach().cpu()]\n",
    "                batch = []\n",
    "        if len(batch) > 0:\n",
    "            with torch.no_grad():\n",
    "                query_embeddings = pooling(model(parser(batch)))['sentence_embedding']\n",
    "                result += [query_embeddings.detach().cpu()]\n",
    "        embs = torch.cat(result, dim=0)\n",
    "        embs /= embs.norm(dim=-1, keepdim=True)\n",
    "        return embs\n",
    "    \n",
    "    def encode(self, sentences, batch_size=32, **kwargs):\n",
    "        \"\"\"\n",
    "        Returns a list of embeddings for the given sentences.\n",
    "        Args:\n",
    "            sentences (`List[str]`): List of sentences to encode\n",
    "            batch_size (`int`): Batch size for the encoding\n",
    "\n",
    "        Returns:\n",
    "            `List[np.ndarray]` or `List[tensor]`: List of embeddings for the given sentences\n",
    "        \"\"\"\n",
    "        return self.encode_corpus(sentences, batch_size=batch_size, **kwargs)\n",
    "        #return self.encode_queries(sentences, batch_size=batch_size, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #262626; text-decoration-color: #262626\">───────────────────────────────────────────────── </span><span style=\"font-weight: bold\">Selected tasks </span><span style=\"color: #262626; text-decoration-color: #262626\"> ─────────────────────────────────────────────────</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[38;5;235m───────────────────────────────────────────────── \u001b[0m\u001b[1mSelected tasks \u001b[0m\u001b[38;5;235m ─────────────────────────────────────────────────\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Classification</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mClassification\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">    - EmotionClassification, <span style=\"color: #626262; text-decoration-color: #626262; font-style: italic\">s2s</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "    - EmotionClassification, \u001b[3;38;5;241ms2s\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/dlabdata1/wendler/.pt201/lib/python3.10/site-packages/huggingface_hub/repocard.py:105: UserWarning: Repo card metadata block was not found. Setting CardData to empty.\n",
      "  warnings.warn(\"Repo card metadata block was not found. Setting CardData to empty.\")\n"
     ]
    }
   ],
   "source": [
    "from mteb import MTEB\n",
    "mymodel = MyModel(model, parser, pooling)\n",
    "evaluation = MTEB(tasks=[\"EmotionClassification\"])\n",
    "evaluation.run(mymodel, batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
