{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from llamawrapper import LlamaHelper\n",
    "import torch\n",
    "import sys\n",
    "sys.path.append('echo-embeddings')\n",
    "from echo_embeddings import EchoEmbeddingsMistral, EchoPooling, EchoParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "42d2b69bde024b458905d2d90f5308c8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "runai = False\n",
    "templates = {\n",
    "    'query': '<s>Instruct:{!%%prompt%%,}\\nQuery:{!%%text%%}\\nQuery again:{%%text%%}{</s>}',\n",
    "    'document': '<s>Document:{!%%text%%}\\nDocument again:{%%text%%}{</s>}',\n",
    "}\n",
    "# Create the model\n",
    "path_to_model = 'jspringer/echo-mistral-7b-instruct-lasttoken'\n",
    "path_to_model = '/dlabscratch1/public/llm_weights/llama2_hf/Llama-2-7b-hf'\n",
    "if runai:\n",
    "    path_to_model = '/dlabscratch1' + path_to_model\n",
    "model = EchoEmbeddingsMistral.from_pretrained(path_to_model, device_map='auto', load_in_8bit=True)\n",
    "model = model.eval()\n",
    "\n",
    "# Create the parser\n",
    "parser = EchoParser(path_to_model, templates, max_length=512)\n",
    "\n",
    "# Create the pooling: strategy can either be mean or last\n",
    "pooling = EchoPooling(strategy='mean')\n",
    "\n",
    "# specify the prompt, queries, and documents\n",
    "prompt = 'Retrieve passages that answer the question'\n",
    "queries = [\n",
    "    'What is the capital of France?',\n",
    "    'What is the capital of Deutschland?',\n",
    "]\n",
    "documents = [\n",
    "    'Paris is the capital of France.',\n",
    "    'Berlin is the capital of Germany.',\n",
    "]\n",
    "\n",
    "query_variables = [{'prompt': prompt, 'text': q} for q in queries]\n",
    "document_variables = [{'text': d} for d in documents]\n",
    "\n",
    "query_tagged = [('query', q) for q in query_variables]\n",
    "document_tagged = [('document', d) for d in document_variables]\n",
    "\n",
    "# Get the tokenized embeddings\n",
    "with torch.no_grad():\n",
    "    query_embeddings = pooling(model(parser(query_tagged)))['sentence_embedding']\n",
    "    document_embeddings = pooling(model(parser(document_tagged)))['sentence_embedding']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 4096])\n",
      "tensor([[0.8921, 0.8638],\n",
      "        [0.7812, 0.8169]], device='cuda:0', dtype=torch.float16)\n"
     ]
    }
   ],
   "source": [
    "query_embeddings /= query_embeddings.norm(dim=-1, keepdim=True)\n",
    "document_embeddings /= document_embeddings.norm(dim=-1, keepdim=True)\n",
    "print(query_embeddings.shape)\n",
    "print(query_embeddings @ document_embeddings.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyModel():\n",
    "    def __init__(self, model, parser, pooling):\n",
    "        self.model = model\n",
    "        self.parser = parser\n",
    "        self.pooling = pooling\n",
    "\n",
    "    def encode_queries(self, queries, batch_size=32, **kwargs):\n",
    "        \"\"\"\n",
    "        Returns a list of embeddings for the given sentences.\n",
    "        Args:\n",
    "            queries (`List[str]`): List of sentences to encode\n",
    "            batch_size (`int`): Batch size for the encoding\n",
    "\n",
    "        Returns:\n",
    "            `List[np.ndarray]` or `List[tensor]`: List of embeddings for the given sentences\n",
    "        \"\"\"\n",
    "        model = self.model\n",
    "        parser = self.parser\n",
    "        pooling = self.pooling\n",
    "\n",
    "        query_variables = [{'prompt': prompt, 'text': q} for q in queries]\n",
    "\n",
    "        query_tagged = [('query', q) for q in query_variables]\n",
    "\n",
    "        # Get the tokenized embeddings\n",
    "        with torch.no_grad():\n",
    "            query_embeddings = pooling(model(parser(query_tagged)))['sentence_embedding']\n",
    "        return query_embeddings.detach().cpu()\n",
    "\n",
    "    def encode_corpus(self, corpus, batch_size=32, **kwargs):\n",
    "        \"\"\"\n",
    "        Returns a list of embeddings for the given sentences.\n",
    "        Args:\n",
    "            corpus (`List[str]` or `List[Dict[str, str]]`): List of sentences to encode\n",
    "                or list of dictionaries with keys \"title\" and \"text\"\n",
    "            batch_size (`int`): Batch size for the encoding\n",
    "\n",
    "        Returns:\n",
    "            `List[np.ndarray]` or `List[tensor]`: List of embeddings for the given sentences\n",
    "        \"\"\"\n",
    "        model = self.model\n",
    "        parser = self.parser\n",
    "        pooling = self.pooling\n",
    "        document_variables = [{'text': d} for d in corpus]\n",
    "\n",
    "        document_tagged = [('document', d) for d in document_variables]\n",
    "\n",
    "        # Get the tokenized embeddings\n",
    "        with torch.no_grad():\n",
    "            document_embeddings = pooling(model(parser(document_tagged)))['sentence_embedding']\n",
    "        return document_embeddings.detach().cpu()\n",
    "    \n",
    "    def encode(self, sentences, batch_size=32, **kwargs):\n",
    "        \"\"\"\n",
    "        Returns a list of embeddings for the given sentences.\n",
    "        Args:\n",
    "            sentences (`List[str]`): List of sentences to encode\n",
    "            batch_size (`int`): Batch size for the encoding\n",
    "\n",
    "        Returns:\n",
    "            `List[np.ndarray]` or `List[tensor]`: List of embeddings for the given sentences\n",
    "        \"\"\"\n",
    "        return self.encode_corpus(sentences, batch_size=batch_size, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #262626; text-decoration-color: #262626\">───────────────────────────────────────────────── </span><span style=\"font-weight: bold\">Selected tasks </span><span style=\"color: #262626; text-decoration-color: #262626\"> ─────────────────────────────────────────────────</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[38;5;235m───────────────────────────────────────────────── \u001b[0m\u001b[1mSelected tasks \u001b[0m\u001b[38;5;235m ─────────────────────────────────────────────────\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Classification</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mClassification\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">    - EmotionClassification, <span style=\"color: #626262; text-decoration-color: #626262; font-style: italic\">s2s</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "    - EmotionClassification, \u001b[3;38;5;241ms2s\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/dlabdata1/wendler/.pt201/lib/python3.10/site-packages/huggingface_hub/repocard.py:105: UserWarning: Repo card metadata block was not found. Setting CardData to empty.\n",
      "  warnings.warn(\"Repo card metadata block was not found. Setting CardData to empty.\")\n",
      "Error while evaluating EmotionClassification: CUDA out of memory. Tried to allocate 4.49 GiB (GPU 0; 11.93 GiB total capacity; 9.78 GiB already allocated; 1.35 GiB free; 10.00 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n"
     ]
    },
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 4.49 GiB (GPU 0; 11.93 GiB total capacity; 9.78 GiB already allocated; 1.35 GiB free; 10.00 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
      "\u001b[1;32m/dlabdata1/wendler/code/llama2-embeddings/EchoEmbeddings.ipynb Cell 5\u001b[0m line \u001b[0;36m4\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Biccluster060.iccluster.epfl.ch/dlabdata1/wendler/code/llama2-embeddings/EchoEmbeddings.ipynb#X11sdnNjb2RlLXJlbW90ZQ%3D%3D?line=1'>2</a>\u001b[0m mymodel \u001b[39m=\u001b[39m MyModel(model, parser, pooling)\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Biccluster060.iccluster.epfl.ch/dlabdata1/wendler/code/llama2-embeddings/EchoEmbeddings.ipynb#X11sdnNjb2RlLXJlbW90ZQ%3D%3D?line=2'>3</a>\u001b[0m evaluation \u001b[39m=\u001b[39m MTEB(tasks\u001b[39m=\u001b[39m[\u001b[39m\"\u001b[39m\u001b[39mEmotionClassification\u001b[39m\u001b[39m\"\u001b[39m])\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2Biccluster060.iccluster.epfl.ch/dlabdata1/wendler/code/llama2-embeddings/EchoEmbeddings.ipynb#X11sdnNjb2RlLXJlbW90ZQ%3D%3D?line=3'>4</a>\u001b[0m evaluation\u001b[39m.\u001b[39;49mrun(mymodel, batch_size\u001b[39m=\u001b[39;49m\u001b[39m32\u001b[39;49m)\n",
      "File \u001b[0;32m/dlabdata1/wendler/.pt201/lib/python3.10/site-packages/mteb/evaluation/MTEB.py:297\u001b[0m, in \u001b[0;36mMTEB.run\u001b[0;34m(self, model, verbosity, output_folder, eval_splits, overwrite_results, raise_error, **kwargs)\u001b[0m\n\u001b[1;32m    295\u001b[0m logger\u001b[39m.\u001b[39merror(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mError while evaluating \u001b[39m\u001b[39m{\u001b[39;00mtask\u001b[39m.\u001b[39mdescription[\u001b[39m'\u001b[39m\u001b[39mname\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m}\u001b[39;00m\u001b[39m: \u001b[39m\u001b[39m{\u001b[39;00me\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    296\u001b[0m \u001b[39mif\u001b[39;00m raise_error:\n\u001b[0;32m--> 297\u001b[0m     \u001b[39mraise\u001b[39;00m e\n\u001b[1;32m    298\u001b[0m logger\u001b[39m.\u001b[39merror(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mPlease check all the error logs at: \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39merr_logs_path\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    299\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mopen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39merr_logs_path, \u001b[39m\"\u001b[39m\u001b[39ma\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mas\u001b[39;00m f_out:\n",
      "File \u001b[0;32m/dlabdata1/wendler/.pt201/lib/python3.10/site-packages/mteb/evaluation/MTEB.py:279\u001b[0m, in \u001b[0;36mMTEB.run\u001b[0;34m(self, model, verbosity, output_folder, eval_splits, overwrite_results, raise_error, **kwargs)\u001b[0m\n\u001b[1;32m    277\u001b[0m \u001b[39mfor\u001b[39;00m split \u001b[39min\u001b[39;00m task_eval_splits:\n\u001b[1;32m    278\u001b[0m     tick \u001b[39m=\u001b[39m time()\n\u001b[0;32m--> 279\u001b[0m     results \u001b[39m=\u001b[39m task\u001b[39m.\u001b[39;49mevaluate(model, split, output_folder\u001b[39m=\u001b[39;49moutput_folder, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    280\u001b[0m     tock \u001b[39m=\u001b[39m time()\n\u001b[1;32m    281\u001b[0m     logger\u001b[39m.\u001b[39minfo(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mEvaluation for \u001b[39m\u001b[39m{\u001b[39;00mtask\u001b[39m.\u001b[39mdescription[\u001b[39m'\u001b[39m\u001b[39mname\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m}\u001b[39;00m\u001b[39m on \u001b[39m\u001b[39m{\u001b[39;00msplit\u001b[39m}\u001b[39;00m\u001b[39m took \u001b[39m\u001b[39m{\u001b[39;00mtock\u001b[39m \u001b[39m\u001b[39m-\u001b[39m\u001b[39m \u001b[39mtick\u001b[39m:\u001b[39;00m\u001b[39m.2f\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m seconds\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m/dlabdata1/wendler/.pt201/lib/python3.10/site-packages/mteb/abstasks/AbsTaskClassification.py:55\u001b[0m, in \u001b[0;36mAbsTaskClassification.evaluate\u001b[0;34m(self, model, eval_split, train_split, **kwargs)\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     54\u001b[0m     logger\u001b[39m.\u001b[39minfo(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39mTask: \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdescription[\u001b[39m'\u001b[39m\u001b[39mname\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m}\u001b[39;00m\u001b[39m, split: \u001b[39m\u001b[39m{\u001b[39;00meval_split\u001b[39m}\u001b[39;00m\u001b[39m. Running...\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m---> 55\u001b[0m     scores \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_evaluate_monolingual(model, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdataset, eval_split, train_split, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     56\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_add_main_score(scores)\n\u001b[1;32m     58\u001b[0m \u001b[39mreturn\u001b[39;00m scores\n",
      "File \u001b[0;32m/dlabdata1/wendler/.pt201/lib/python3.10/site-packages/mteb/abstasks/AbsTaskClassification.py:90\u001b[0m, in \u001b[0;36mAbsTaskClassification._evaluate_monolingual\u001b[0;34m(self, model, dataset, eval_split, train_split, **kwargs)\u001b[0m\n\u001b[1;32m     87\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     88\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mMethod \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmethod\u001b[39m}\u001b[39;00m\u001b[39m not supported\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m---> 90\u001b[0m     scores_exp, test_cache \u001b[39m=\u001b[39m evaluator(model, test_cache\u001b[39m=\u001b[39;49mtest_cache)\n\u001b[1;32m     91\u001b[0m     scores\u001b[39m.\u001b[39mappend(scores_exp)\n\u001b[1;32m     93\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_experiments \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n",
      "File \u001b[0;32m/dlabdata1/wendler/.pt201/lib/python3.10/site-packages/mteb/evaluation/evaluators/ClassificationEvaluator.py:214\u001b[0m, in \u001b[0;36mlogRegClassificationEvaluator.__call__\u001b[0;34m(self, model, test_cache)\u001b[0m\n\u001b[1;32m    212\u001b[0m logger\u001b[39m.\u001b[39minfo(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mEncoding \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msentences_test)\u001b[39m}\u001b[39;00m\u001b[39m test sentences...\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    213\u001b[0m \u001b[39mif\u001b[39;00m test_cache \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 214\u001b[0m     X_test \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39masarray(model\u001b[39m.\u001b[39;49mencode(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msentences_test, batch_size\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbatch_size))\n\u001b[1;32m    215\u001b[0m     test_cache \u001b[39m=\u001b[39m X_test\n\u001b[1;32m    216\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "\u001b[1;32m/dlabdata1/wendler/code/llama2-embeddings/EchoEmbeddings.ipynb Cell 5\u001b[0m line \u001b[0;36m6\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Biccluster060.iccluster.epfl.ch/dlabdata1/wendler/code/llama2-embeddings/EchoEmbeddings.ipynb#X11sdnNjb2RlLXJlbW90ZQ%3D%3D?line=52'>53</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mencode\u001b[39m(\u001b[39mself\u001b[39m, sentences, batch_size\u001b[39m=\u001b[39m\u001b[39m32\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Biccluster060.iccluster.epfl.ch/dlabdata1/wendler/code/llama2-embeddings/EchoEmbeddings.ipynb#X11sdnNjb2RlLXJlbW90ZQ%3D%3D?line=53'>54</a>\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Biccluster060.iccluster.epfl.ch/dlabdata1/wendler/code/llama2-embeddings/EchoEmbeddings.ipynb#X11sdnNjb2RlLXJlbW90ZQ%3D%3D?line=54'>55</a>\u001b[0m \u001b[39m    Returns a list of embeddings for the given sentences.\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Biccluster060.iccluster.epfl.ch/dlabdata1/wendler/code/llama2-embeddings/EchoEmbeddings.ipynb#X11sdnNjb2RlLXJlbW90ZQ%3D%3D?line=55'>56</a>\u001b[0m \u001b[39m    Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Biccluster060.iccluster.epfl.ch/dlabdata1/wendler/code/llama2-embeddings/EchoEmbeddings.ipynb#X11sdnNjb2RlLXJlbW90ZQ%3D%3D?line=60'>61</a>\u001b[0m \u001b[39m        `List[np.ndarray]` or `List[tensor]`: List of embeddings for the given sentences\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Biccluster060.iccluster.epfl.ch/dlabdata1/wendler/code/llama2-embeddings/EchoEmbeddings.ipynb#X11sdnNjb2RlLXJlbW90ZQ%3D%3D?line=61'>62</a>\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2Biccluster060.iccluster.epfl.ch/dlabdata1/wendler/code/llama2-embeddings/EchoEmbeddings.ipynb#X11sdnNjb2RlLXJlbW90ZQ%3D%3D?line=62'>63</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mencode_corpus(sentences, batch_size\u001b[39m=\u001b[39;49mbatch_size, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "\u001b[1;32m/dlabdata1/wendler/code/llama2-embeddings/EchoEmbeddings.ipynb Cell 5\u001b[0m line \u001b[0;36m5\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Biccluster060.iccluster.epfl.ch/dlabdata1/wendler/code/llama2-embeddings/EchoEmbeddings.ipynb#X11sdnNjb2RlLXJlbW90ZQ%3D%3D?line=47'>48</a>\u001b[0m \u001b[39m# Get the tokenized embeddings\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Biccluster060.iccluster.epfl.ch/dlabdata1/wendler/code/llama2-embeddings/EchoEmbeddings.ipynb#X11sdnNjb2RlLXJlbW90ZQ%3D%3D?line=48'>49</a>\u001b[0m \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mno_grad():\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2Biccluster060.iccluster.epfl.ch/dlabdata1/wendler/code/llama2-embeddings/EchoEmbeddings.ipynb#X11sdnNjb2RlLXJlbW90ZQ%3D%3D?line=49'>50</a>\u001b[0m     document_embeddings \u001b[39m=\u001b[39m pooling(model(parser(document_tagged)))[\u001b[39m'\u001b[39m\u001b[39msentence_embedding\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Biccluster060.iccluster.epfl.ch/dlabdata1/wendler/code/llama2-embeddings/EchoEmbeddings.ipynb#X11sdnNjb2RlLXJlbW90ZQ%3D%3D?line=50'>51</a>\u001b[0m \u001b[39mreturn\u001b[39;00m document_embeddings\u001b[39m.\u001b[39mdetach()\u001b[39m.\u001b[39mcpu()\n",
      "File \u001b[0;32m/dlabdata1/wendler/.pt201/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m/dlabdata1/wendler/code/llama2-embeddings/echo-embeddings/echo_embeddings.py:143\u001b[0m, in \u001b[0;36mEchoEmbeddingsMistral.forward\u001b[0;34m(self, xs)\u001b[0m\n\u001b[1;32m    138\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, xs):\n\u001b[1;32m    139\u001b[0m     inputs \u001b[39m=\u001b[39m {\n\u001b[1;32m    140\u001b[0m         \u001b[39m'\u001b[39m\u001b[39minput_ids\u001b[39m\u001b[39m'\u001b[39m: xs[\u001b[39m'\u001b[39m\u001b[39minput_ids\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mto(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel\u001b[39m.\u001b[39mdevice),\n\u001b[1;32m    141\u001b[0m         \u001b[39m'\u001b[39m\u001b[39mattention_mask\u001b[39m\u001b[39m'\u001b[39m: xs[\u001b[39m'\u001b[39m\u001b[39mattention_mask\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mto(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel\u001b[39m.\u001b[39mdevice),\n\u001b[1;32m    142\u001b[0m     }\n\u001b[0;32m--> 143\u001b[0m     outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmodel(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49minputs)\u001b[39m.\u001b[39mlast_hidden_state\n\u001b[1;32m    144\u001b[0m     xs\u001b[39m.\u001b[39mupdate({\n\u001b[1;32m    145\u001b[0m         \u001b[39m'\u001b[39m\u001b[39mtoken_embeddings\u001b[39m\u001b[39m'\u001b[39m: outputs,\n\u001b[1;32m    146\u001b[0m     })\n\u001b[1;32m    147\u001b[0m     \u001b[39mreturn\u001b[39;00m xs\n",
      "File \u001b[0;32m/dlabdata1/wendler/.pt201/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m/dlabdata1/wendler/.pt201/lib/python3.10/site-packages/accelerate/hooks.py:164\u001b[0m, in \u001b[0;36madd_hook_to_module.<locals>.new_forward\u001b[0;34m(module, *args, **kwargs)\u001b[0m\n\u001b[1;32m    162\u001b[0m         output \u001b[39m=\u001b[39m module\u001b[39m.\u001b[39m_old_forward(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m    163\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 164\u001b[0m     output \u001b[39m=\u001b[39m module\u001b[39m.\u001b[39;49m_old_forward(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    165\u001b[0m \u001b[39mreturn\u001b[39;00m module\u001b[39m.\u001b[39m_hf_hook\u001b[39m.\u001b[39mpost_forward(module, output)\n",
      "File \u001b[0;32m/dlabdata1/wendler/.pt201/lib/python3.10/site-packages/transformers/models/llama/modeling_llama.py:922\u001b[0m, in \u001b[0;36mLlamaModel.forward\u001b[0;34m(self, input_ids, attention_mask, position_ids, past_key_values, inputs_embeds, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    912\u001b[0m     layer_outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_gradient_checkpointing_func(\n\u001b[1;32m    913\u001b[0m         decoder_layer\u001b[39m.\u001b[39m\u001b[39m__call__\u001b[39m,\n\u001b[1;32m    914\u001b[0m         hidden_states,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    919\u001b[0m         use_cache,\n\u001b[1;32m    920\u001b[0m     )\n\u001b[1;32m    921\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 922\u001b[0m     layer_outputs \u001b[39m=\u001b[39m decoder_layer(\n\u001b[1;32m    923\u001b[0m         hidden_states,\n\u001b[1;32m    924\u001b[0m         attention_mask\u001b[39m=\u001b[39;49mattention_mask,\n\u001b[1;32m    925\u001b[0m         position_ids\u001b[39m=\u001b[39;49mposition_ids,\n\u001b[1;32m    926\u001b[0m         past_key_value\u001b[39m=\u001b[39;49mpast_key_value,\n\u001b[1;32m    927\u001b[0m         output_attentions\u001b[39m=\u001b[39;49moutput_attentions,\n\u001b[1;32m    928\u001b[0m         use_cache\u001b[39m=\u001b[39;49muse_cache,\n\u001b[1;32m    929\u001b[0m     )\n\u001b[1;32m    931\u001b[0m hidden_states \u001b[39m=\u001b[39m layer_outputs[\u001b[39m0\u001b[39m]\n\u001b[1;32m    933\u001b[0m \u001b[39mif\u001b[39;00m use_cache:\n",
      "File \u001b[0;32m/dlabdata1/wendler/.pt201/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m/dlabdata1/wendler/.pt201/lib/python3.10/site-packages/accelerate/hooks.py:164\u001b[0m, in \u001b[0;36madd_hook_to_module.<locals>.new_forward\u001b[0;34m(module, *args, **kwargs)\u001b[0m\n\u001b[1;32m    162\u001b[0m         output \u001b[39m=\u001b[39m module\u001b[39m.\u001b[39m_old_forward(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m    163\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 164\u001b[0m     output \u001b[39m=\u001b[39m module\u001b[39m.\u001b[39;49m_old_forward(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    165\u001b[0m \u001b[39mreturn\u001b[39;00m module\u001b[39m.\u001b[39m_hf_hook\u001b[39m.\u001b[39mpost_forward(module, output)\n",
      "File \u001b[0;32m/dlabdata1/wendler/.pt201/lib/python3.10/site-packages/transformers/models/llama/modeling_llama.py:669\u001b[0m, in \u001b[0;36mLlamaDecoderLayer.forward\u001b[0;34m(self, hidden_states, attention_mask, position_ids, past_key_value, output_attentions, use_cache, **kwargs)\u001b[0m\n\u001b[1;32m    663\u001b[0m     warnings\u001b[39m.\u001b[39mwarn(\n\u001b[1;32m    664\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mPassing `padding_mask` is deprecated and will be removed in v4.37. Please make sure use `attention_mask` instead.`\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    665\u001b[0m     )\n\u001b[1;32m    667\u001b[0m residual \u001b[39m=\u001b[39m hidden_states\n\u001b[0;32m--> 669\u001b[0m hidden_states \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49minput_layernorm(hidden_states)\n\u001b[1;32m    671\u001b[0m \u001b[39m# Self Attention\u001b[39;00m\n\u001b[1;32m    672\u001b[0m hidden_states, self_attn_weights, present_key_value \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mself_attn(\n\u001b[1;32m    673\u001b[0m     hidden_states\u001b[39m=\u001b[39mhidden_states,\n\u001b[1;32m    674\u001b[0m     attention_mask\u001b[39m=\u001b[39mattention_mask,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    679\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs,\n\u001b[1;32m    680\u001b[0m )\n",
      "File \u001b[0;32m/dlabdata1/wendler/.pt201/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m/dlabdata1/wendler/.pt201/lib/python3.10/site-packages/accelerate/hooks.py:164\u001b[0m, in \u001b[0;36madd_hook_to_module.<locals>.new_forward\u001b[0;34m(module, *args, **kwargs)\u001b[0m\n\u001b[1;32m    162\u001b[0m         output \u001b[39m=\u001b[39m module\u001b[39m.\u001b[39m_old_forward(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m    163\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 164\u001b[0m     output \u001b[39m=\u001b[39m module\u001b[39m.\u001b[39;49m_old_forward(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    165\u001b[0m \u001b[39mreturn\u001b[39;00m module\u001b[39m.\u001b[39m_hf_hook\u001b[39m.\u001b[39mpost_forward(module, output)\n",
      "File \u001b[0;32m/dlabdata1/wendler/.pt201/lib/python3.10/site-packages/transformers/models/llama/modeling_llama.py:105\u001b[0m, in \u001b[0;36mLlamaRMSNorm.forward\u001b[0;34m(self, hidden_states)\u001b[0m\n\u001b[1;32m    103\u001b[0m input_dtype \u001b[39m=\u001b[39m hidden_states\u001b[39m.\u001b[39mdtype\n\u001b[1;32m    104\u001b[0m hidden_states \u001b[39m=\u001b[39m hidden_states\u001b[39m.\u001b[39mto(torch\u001b[39m.\u001b[39mfloat32)\n\u001b[0;32m--> 105\u001b[0m variance \u001b[39m=\u001b[39m hidden_states\u001b[39m.\u001b[39;49mpow(\u001b[39m2\u001b[39;49m)\u001b[39m.\u001b[39mmean(\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m, keepdim\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m    106\u001b[0m hidden_states \u001b[39m=\u001b[39m hidden_states \u001b[39m*\u001b[39m torch\u001b[39m.\u001b[39mrsqrt(variance \u001b[39m+\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mvariance_epsilon)\n\u001b[1;32m    107\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mweight \u001b[39m*\u001b[39m hidden_states\u001b[39m.\u001b[39mto(input_dtype)\n",
      "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 4.49 GiB (GPU 0; 11.93 GiB total capacity; 9.78 GiB already allocated; 1.35 GiB free; 10.00 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"
     ]
    }
   ],
   "source": [
    "from mteb import MTEB\n",
    "mymodel = MyModel(model, parser, pooling)\n",
    "evaluation = MTEB(tasks=[\"EmotionClassification\"])\n",
    "evaluation.run(mymodel, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
